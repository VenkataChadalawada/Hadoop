
- hands on with Hortonworks sandbox
- worked on Ambari interface
- wrote mapreduce programs in python
- experienced in writing pig scripts in piglatin
- executed hive queries on Ambari hive interface
- created spark program to extract toprated movies & least ranked movies in both Spark & Spark 2.0
- defined RDD's & data frames in spark to retrive spark's internal Directed Acyclic Graphs.
- done partitions of data from single source using partion in hive
- wrote joins in hive to combine views and tables to bring the final result
- creating tables in mysql writing complex queries with joins groups in mysql
- importing mysql tables into hdfs and hive using sqoop
- exporting tables from hdfs to mysql using sqoop
- runing hbase server and connecting to it through python client & importing data into Hbase via starbase & portforwarding
- interacting through Hbase shell and creating tables, scanning, dropping
- using pig to import data into HBase using pig.backend.hadoop.hbase.HBaseStorage
- Installing Datastax Cassandra in the hortonworks centos sandbox and cqlsh for shell interaction
- Cassandra - wrting CQL commands, creating keyspaces and tables
- performing analytics using spark in cassandra
- creating a spark session, getting the raw data converting that to a DataFrame and writing it into Cassandra
- Reading it back from cassandra into a new dataframe 
